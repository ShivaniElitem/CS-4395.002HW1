{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d97d2c37-94c6-4859-9f4b-053d0306a77d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d97d2c37-94c6-4859-9f4b-053d0306a77d",
        "outputId": "4b83d95a-6ef3-4d0f-ccec-32b003113dab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Corpus Sample: [['i', 'booked', 'two', 'rooms', 'four', 'months', 'in', 'advance', 'at', 'the', 'talbott', '.', 'we', 'were', 'placed', 'on', 'the', 'top', 'floor', 'next', 'to', 'the', 'elevators', ',', 'which', 'are', 'used', 'all', 'night', 'long', '.', 'when', 'speaking', 'to', 'the', 'front', 'desk', ',', 'i', 'was', 'told', 'that', 'they', 'were', 'simply', 'honoring', 'my', 'request', 'for', 'an', 'upper', 'floor', ',', 'which', 'i', 'had', 'requested', 'for', 'a', 'better', 'view', '.', 'i', 'am', 'looking', 'at', 'a', 'brick', 'wall', ',', 'and', 'getting', 'no', 'sleep', '.', 'he', 'also', 'told', 'me', 'that', 'they', 'had', 'received', 'complaints', 'before', 'from', 'guests', 'on', 'the', '16th', 'floor', ',', 'and', 'were', 'aware', 'of', 'the', 'noise', 'problem', '.', 'why', 'then', 'did', 'they', 'place', 'us', 'on', 'this', 'floor', 'when', 'the', 'hotel', 'is', 'not', 'totally', 'booked', '?', 'a', 'request', 'for', 'an', 'upper', 'floor', 'does', 'not', 'constitute', 'placing', 'someone', 'on', 'the', 'top', 'floor', 'and', 'using', 'that', 'request', 'to', 'justify', 'this', '.', 'if', 'you', 'decide', 'to', 'stay', 'here', ',', 'request', 'a', 'room', 'on', 'a', 'lower', 'floor', 'and', 'away', 'from', 'the', 'elevator', '!', 'i', 'spoke', 'at', 'length', 'when', 'booking', 'my', 'two', 'rooms', 'about', 'my', 'preferences', '.', 'this', 'is', 'simply', 'poor', 'treatment', 'of', 'a', 'guest', 'whom', 'they', 'believed', 'would', 'not', 'complain', '.']]\n",
            "Validation Corpus Sample: [['i', 'stayed', 'for', 'four', 'nights', 'while', 'attending', 'a', 'conference', '.', 'the', 'hotel', 'is', 'in', 'a', 'great', 'spot', '-', 'easy', 'walk', 'to', 'michigan', 'ave', 'shopping', 'or', 'rush', 'st.', ',', 'but', 'just', 'off', 'the', 'busy', 'streets', '.', 'the', 'room', 'i', 'had', 'was', 'spacious', ',', 'and', 'very', 'well-appointed', '.', 'the', 'staff', 'was', 'friendly', ',', 'and', 'the', 'fitness', 'center', ',', 'while', 'not', 'huge', ',', 'was', 'well-equipped', 'and', 'clean', '.', 'i', \"'ve\", 'stayed', 'at', 'a', 'number', 'of', 'hotels', 'in', 'chicago', ',', 'and', 'this', 'one', 'is', 'my', 'favorite', '.', 'internet', 'was', \"n't\", 'free', ',', 'but', 'at', '$', '10', 'for', '24', 'hours', 'is', 'cheaper', 'than', 'most', 'business', 'hotels', ',', 'and', 'it', 'worked', 'very', 'well', '.']]\n"
          ]
        }
      ],
      "source": [
        "## IMPORT AND LOAD CORPORA ##\n",
        "\n",
        "# Import NumPy (Numerical Python) package with alias np\n",
        "import numpy as np\n",
        "# Counter subclass: used to count hashable objects\n",
        "# -- for ngram counts\n",
        "from collections import Counter\n",
        "# islice: iterator function for help with print statements\n",
        "from itertools import islice\n",
        "\n",
        "# Function: load corpus txt file and tokenize\n",
        "def load_corpus(file_path):\n",
        "    with open(file_path, 'r') as text_file:\n",
        "        lines = text_file.readlines()\n",
        "    # tokenize: remove excess whitespace, all lower-case, split by whitespace\n",
        "    corpus = [line.strip().lower().split() for line in lines]\n",
        "    return corpus\n",
        "\n",
        "# Load corpora\n",
        "train_corpus = load_corpus('train.txt')\n",
        "val_corpus = load_corpus('val.txt')\n",
        "\n",
        "# (OPTIONAL) Show preview of the split data\n",
        "print(\"Train Corpus Sample:\", train_corpus[:1])  # Show first line\n",
        "print(\"Validation Corpus Sample:\", val_corpus[:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DbzqVIl0Px9Q",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbzqVIl0Px9Q",
        "outputId": "324bb55c-a51c-4b7c-ee71-e8d63b30d183"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Corpus Sample: [['i', 'booked', 'two', 'rooms', 'four', 'months', 'in', 'advance', 'at', 'the', 'talbott', '.', 'we', 'were', 'placed', 'on', 'the', 'top', 'floor', 'next', 'to', 'the', 'elevators', ',', 'which', 'are', 'used', 'all', 'night', 'long', '.', 'when', 'speaking', 'to', 'the', 'front', 'desk', ',', 'i', 'was', 'told', 'that', 'they', 'were', 'simply', 'honoring', 'my', 'request', 'for', 'an', 'upper', 'floor', ',', 'which', 'i', 'had', 'requested', 'for', 'a', 'better', 'view', '.', 'i', 'am', 'looking', 'at', 'a', 'brick', 'wall', ',', 'and', 'getting', 'no', 'sleep', '.', 'he', 'also', 'told', 'me', 'that', 'they', 'had', 'received', 'complaints', 'before', 'from', 'guests', 'on', 'the', '16th', 'floor', ',', 'and', 'were', 'aware', 'of', 'the', 'noise', 'problem', '.', 'why', 'then', 'did', 'they', 'place', 'us', 'on', 'this', 'floor', 'when', 'the', 'hotel', 'is', 'not', 'totally', 'booked', '?', 'a', 'request', 'for', 'an', 'upper', 'floor', 'does', 'not', 'constitute', 'placing', 'someone', 'on', 'the', 'top', 'floor', 'and', 'using', 'that', 'request', 'to', 'justify', 'this', '.', 'if', 'you', 'decide', 'to', 'stay', 'here', ',', 'request', 'a', 'room', 'on', 'a', 'lower', 'floor', 'and', 'away', 'from', 'the', 'elevator', '!', 'i', 'spoke', 'at', 'length', 'when', 'booking', 'my', 'two', 'rooms', 'about', 'my', 'preferences', '.', 'this', 'is', 'simply', 'poor', 'treatment', 'of', 'a', 'guest', 'whom', 'they', 'believed', 'would', 'not', 'complain', '.']]\n",
            "Modified Corpus Sample: [['i', 'booked', 'two', 'rooms', 'four', 'months', 'in', 'advance', 'at', 'the', 'talbott', '.', 'we', 'were', 'placed', 'on', 'the', 'top', 'floor', 'next', 'to', 'the', 'elevators', ',', 'which', 'are', 'used', 'all', 'night', 'long', '.', 'when', 'speaking', 'to', 'the', 'front', 'desk', ',', 'i', 'was', 'told', 'that', 'they', 'were', 'simply', '<UNK>', 'my', 'request', 'for', 'an', 'upper', 'floor', ',', 'which', 'i', 'had', 'requested', 'for', 'a', 'better', 'view', '.', 'i', 'am', 'looking', 'at', 'a', 'brick', 'wall', ',', 'and', 'getting', 'no', 'sleep', '.', 'he', 'also', 'told', 'me', 'that', 'they', 'had', 'received', 'complaints', 'before', 'from', 'guests', 'on', 'the', '<UNK>', 'floor', ',', 'and', 'were', 'aware', 'of', 'the', 'noise', 'problem', '.', 'why', 'then', 'did', 'they', 'place', 'us', 'on', 'this', 'floor', 'when', 'the', 'hotel', 'is', 'not', 'totally', 'booked', '?', 'a', 'request', 'for', 'an', 'upper', 'floor', 'does', 'not', '<UNK>', '<UNK>', 'someone', 'on', 'the', 'top', 'floor', 'and', 'using', 'that', 'request', 'to', '<UNK>', 'this', '.', 'if', 'you', '<UNK>', 'to', 'stay', 'here', ',', 'request', 'a', 'room', 'on', 'a', 'lower', 'floor', 'and', 'away', 'from', 'the', 'elevator', '!', 'i', 'spoke', 'at', '<UNK>', 'when', 'booking', 'my', 'two', 'rooms', 'about', 'my', '<UNK>', '.', 'this', 'is', 'simply', 'poor', 'treatment', 'of', 'a', 'guest', 'whom', 'they', '<UNK>', 'would', 'not', 'complain', '.']]\n"
          ]
        }
      ],
      "source": [
        "## UNKNOWN WORD HANDLING ##\n",
        "\n",
        "# Replace words below a threshold with <UNK>\n",
        "\n",
        "# Step 1: Count word frequencies\n",
        "word_counts = Counter(word for sentence in train_corpus for word in sentence)\n",
        "\n",
        "# Step 2: Set a threshold\n",
        "# -- if a word appears less than 2 times in the training corpus, replace it\n",
        "# -- otherwise, add it to the vocabulary list\n",
        "threshold = 2\n",
        "vocab = {word for word, count in word_counts.items() if count > threshold}\n",
        "\n",
        "# Replace rare words with `<UNK>` in a single line using list comprehension\n",
        "train_corpus_modified = [[word if word in vocab else \"<UNK>\" for word in sentence] for sentence in train_corpus]\n",
        "\n",
        "# Output results\n",
        "print(\"Original Corpus Sample:\", train_corpus[:1])\n",
        "print(\"Modified Corpus Sample:\", train_corpus_modified[:1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "807afed4-0c10-43e1-987b-3407a04c5eea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "807afed4-0c10-43e1-987b-3407a04c5eea",
        "outputId": "1cf3aaac-8727-46eb-929e-00ea00f94f31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First 10 Unigram Counts and Probabilities:\n",
            "i: 1706, 0.0190\n",
            "booked: 86, 0.0010\n",
            "two: 128, 0.0014\n",
            "rooms: 201, 0.0022\n",
            "four: 20, 0.0002\n",
            "months: 8, 0.0001\n",
            "in: 1259, 0.0140\n",
            "advance: 7, 0.0001\n",
            "at: 745, 0.0083\n",
            "the: 5292, 0.0590\n"
          ]
        }
      ],
      "source": [
        "## COMPUTE UNIGRAM COUNT AND PROBABILITY ##\n",
        "\n",
        "# Flattens all lines into a single line\n",
        "line_in_train_corpus = [word for line in train_corpus_modified for word in line]\n",
        "\n",
        "# Calculate frequency for each unigram in the training corpus (after <UNK> replacement)\n",
        "unigram_freq = Counter(line_in_train_corpus)\n",
        "# Sum word frequencies to get total words in the corpus\n",
        "total_words = sum(unigram_freq.values())\n",
        "\n",
        "# Calculate probabilites for unigrams (after <UNK> replacement)\n",
        "unigram_probs = {word: count / total_words for word, count in unigram_freq.items()}\n",
        "\n",
        "# Print first 10 unigram counts and probabilities\n",
        "print(\"First 10 Unigram Counts and Probabilities:\")\n",
        "for word, count in islice(unigram_freq.items(), 10):\n",
        "    print(f\"{word}: {count}, {unigram_probs.get(word, 0):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DWENBoarp_r0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWENBoarp_r0",
        "outputId": "6d290cfd-8866-4cd2-8ef6-aba9f6dcf8bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First 10 Bigram Counts and Probabilites:\n",
            "('i', 'booked'): 21, 0.0123\n",
            "('booked', 'two'): 1, 0.0116\n",
            "('two', 'rooms'): 3, 0.0234\n",
            "('rooms', 'four'): 1, 0.0050\n",
            "('four', 'months'): 1, 0.0500\n",
            "('months', 'in'): 2, 0.2500\n",
            "('in', 'advance'): 7, 0.0056\n",
            "('advance', 'at'): 1, 0.1429\n",
            "('at', 'the'): 332, 0.4456\n",
            "('the', 'talbott'): 26, 0.0049\n"
          ]
        }
      ],
      "source": [
        "## COMPUTE BIGRAM COUNT AND PROBABILITY ##\n",
        "\n",
        "# Flatten all lines into a single line\n",
        "line_in_train_corpus = [word for line in train_corpus_modified for word in line]\n",
        "\n",
        "# Calculate count of bigrams in the training corpus (after <UNK> replacement)\n",
        "bigram_counts = Counter()\n",
        "\n",
        "for i in range(len(line_in_train_corpus) - 1):  # Loop through words in the line\n",
        "    bigram = (line_in_train_corpus[i], line_in_train_corpus[i + 1])  # Create bigram tuple\n",
        "    bigram_counts[bigram] += 1  # Update count\n",
        "\n",
        "# Calculate probabilities for bigrams (after <UNK> replacement)\n",
        "bigram_probs = {bigram: count / unigram_freq.get(bigram[0], 1) for bigram, count in bigram_counts.items()} #a little confused on this formula, autocomplete code helped me\n",
        "\n",
        "# Print first 10 bigram counts and probabilities\n",
        "print(\"First 10 Bigram Counts and Probabilites:\")\n",
        "for bigram, count in islice(bigram_counts.items(), 10):\n",
        "    print(f\"{bigram}: {count}, {bigram_probs.get(bigram, 0):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rmnzyM-Kxg_a",
      "metadata": {
        "id": "rmnzyM-Kxg_a"
      },
      "outputs": [],
      "source": [
        "## Implement at least two smoothing techniques (e.g., Laplace, Add-k smoothing) ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cbcfcc5-9d92-4c8b-b4a9-58bf2f921585",
      "metadata": {
        "id": "3cbcfcc5-9d92-4c8b-b4a9-58bf2f921585",
        "outputId": "f1169b34-b75d-4316-ea14-c6abadb1787e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Smoothed Unigram Probabilities:\n",
            "i: 0.0186\n",
            "booked: 0.0009\n",
            "two: 0.0014\n",
            "rooms: 0.0022\n",
            "four: 0.0002\n",
            "months: 0.0001\n",
            "in: 0.0137\n",
            "advance: 0.0001\n",
            "at: 0.0081\n",
            "the: 0.0576\n"
          ]
        }
      ],
      "source": [
        "## LAPLACE SMOOTHING: UNIGRAM PROBABILITIES ##\n",
        "\n",
        "V = len(unigram_freq)  # Vocab size\n",
        "\n",
        "# Apply Laplace smoothing to all unigram counts\n",
        "unigram_probs_smoothed = {word: (count + 1) / (sum(unigram_freq.values()) + V) for word, count in unigram_freq.items()}\n",
        "\n",
        "# Print unigram probabilities after adding 1 to all counts for Laplace smoothing\n",
        "print(\"Smoothed Unigram Probabilities:\")\n",
        "for word, prob in islice(unigram_probs_smoothed.items(),10):\n",
        "    print(f\"{word}: {prob:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "txqq1PHexmM7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txqq1PHexmM7",
        "outputId": "a4976737-26b3-44c4-db68-41e3fc1ed501"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Smoothed Bigram Probabilities:\n",
            "('i', 'booked'): 0.0056\n",
            "('booked', 'two'): 0.0009\n",
            "('two', 'rooms'): 0.0017\n",
            "('rooms', 'four'): 0.0008\n",
            "('four', 'months'): 0.0009\n",
            "('months', 'in'): 0.0013\n",
            "('in', 'advance'): 0.0023\n",
            "('advance', 'at'): 0.0009\n",
            "('at', 'the'): 0.1113\n",
            "('the', 'talbott'): 0.0036\n"
          ]
        }
      ],
      "source": [
        "## LAPLACE SMOOTHING: BIGRAM PROBABILIES ##\n",
        "\n",
        "# Apply Laplace smoothing to all bigram counts\n",
        "bigram_probs_smoothed = {bigram: (count + 1) / (unigram_freq.get(bigram[0], 0) + V) for bigram, count in bigram_counts.items()}\n",
        "\n",
        "# Print bigram probability after added 1 to all counts for Laplace smoothing\n",
        "print(\"Smoothed Bigram Probabilities:\")\n",
        "for bigram, prob in islice(bigram_probs_smoothed.items(), 10):\n",
        "    print(f\"{bigram}: {prob:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HhDUeup2x-cP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhDUeup2x-cP",
        "outputId": "e5742c9f-22b2-417c-86dd-8d0619eb63e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Add-k Smoothed Unigram Probabilities:\n",
            "K = 0.01:\n",
            "i: 0.0190\n",
            "booked: 0.0010\n",
            "two: 0.0014\n",
            "rooms: 0.0022\n",
            "four: 0.0002\n",
            "months: 0.0001\n",
            "in: 0.0140\n",
            "advance: 0.0001\n",
            "at: 0.0083\n",
            "the: 0.0590\n",
            "K = 0.1:\n",
            "i: 0.0190\n",
            "booked: 0.0010\n",
            "two: 0.0014\n",
            "rooms: 0.0022\n",
            "four: 0.0002\n",
            "months: 0.0001\n",
            "in: 0.0140\n",
            "advance: 0.0001\n",
            "at: 0.0083\n",
            "the: 0.0589\n",
            "K = 0.3:\n",
            "i: 0.0189\n",
            "booked: 0.0010\n",
            "two: 0.0014\n",
            "rooms: 0.0022\n",
            "four: 0.0002\n",
            "months: 0.0001\n",
            "in: 0.0139\n",
            "advance: 0.0001\n",
            "at: 0.0082\n",
            "the: 0.0586\n",
            "K = 5:\n",
            "i: 0.0170\n",
            "booked: 0.0009\n",
            "two: 0.0013\n",
            "rooms: 0.0020\n",
            "four: 0.0002\n",
            "months: 0.0001\n",
            "in: 0.0125\n",
            "advance: 0.0001\n",
            "at: 0.0074\n",
            "the: 0.0525\n"
          ]
        }
      ],
      "source": [
        "## K-SMOOTHING: UNIGRAM - multiple values (a-d) ##\n",
        "\n",
        "ka = 0.01\n",
        "kb = 0.1\n",
        "kc = 0.3\n",
        "kd = 5\n",
        "\n",
        "# Apply K-Smoothing values ka -> kd\n",
        "unigram_probs_addka = {word: (count + ka) / (sum(unigram_freq.values()) + ka * V) for word, count in unigram_freq.items()}\n",
        "unigram_probs_addkb = {word: (count + kb) / (sum(unigram_freq.values()) + kb * V) for word, count in unigram_freq.items()}\n",
        "unigram_probs_addkc = {word: (count + kc) / (sum(unigram_freq.values()) + kc * V) for word, count in unigram_freq.items()}\n",
        "unigram_probs_addkd = {word: (count + kd) / (sum(unigram_freq.values()) + kd * V) for word, count in unigram_freq.items()}\n",
        "\n",
        "print(\"Add-k Smoothed Unigram Probabilities:\")\n",
        "print(\"K = 0.01:\")\n",
        "for word, prob in islice(unigram_probs_addka.items(), 10):\n",
        "    print(f\"{word}: {prob:.4f}\")\n",
        "print(\"K = 0.1:\")\n",
        "for word, prob in islice(unigram_probs_addkb.items(), 10):\n",
        "    print(f\"{word}: {prob:.4f}\")\n",
        "print(\"K = 0.3:\")\n",
        "for word, prob in islice(unigram_probs_addkc.items(), 10):\n",
        "    print(f\"{word}: {prob:.4f}\")\n",
        "print(\"K = 5:\")\n",
        "for word, prob in islice(unigram_probs_addkd.items(), 10):\n",
        "    print(f\"{word}: {prob:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aJ9ZwkrVzpdC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJ9ZwkrVzpdC",
        "outputId": "6596ffbb-a297-4f40-cc48-f1bcf6c9f007"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Add-k Smoothed Bigram Probabilities:\n",
            "K = 0.01:\n",
            "('i', 'booked'): 0.0122\n",
            "('booked', 'two'): 0.0093\n",
            "('two', 'rooms'): 0.0200\n",
            "('rooms', 'four'): 0.0045\n",
            "('four', 'months'): 0.0238\n",
            "('months', 'in'): 0.0660\n",
            "('in', 'advance'): 0.0055\n",
            "('advance', 'at'): 0.0343\n",
            "('at', 'the'): 0.4326\n",
            "('the', 'talbott'): 0.0049\n",
            "K = 0.1:\n",
            "('i', 'booked'): 0.0109\n",
            "('booked', 'two'): 0.0035\n",
            "('two', 'rooms'): 0.0088\n",
            "('rooms', 'four'): 0.0026\n",
            "('four', 'months'): 0.0045\n",
            "('months', 'in'): 0.0090\n",
            "('in', 'advance'): 0.0048\n",
            "('advance', 'at'): 0.0047\n",
            "('at', 'the'): 0.3425\n",
            "('the', 'talbott'): 0.0047\n",
            "K = 0.3:\n",
            "('i', 'booked'): 0.0089\n",
            "('booked', 'two'): 0.0017\n",
            "('two', 'rooms'): 0.0041\n",
            "('rooms', 'four'): 0.0015\n",
            "('four', 'months'): 0.0019\n",
            "('months', 'in'): 0.0034\n",
            "('in', 'advance'): 0.0038\n",
            "('advance', 'at'): 0.0019\n",
            "('at', 'the'): 0.2342\n",
            "('the', 'talbott'): 0.0044\n",
            "K = 5:\n",
            "('i', 'booked'): 0.0020\n",
            "('booked', 'two'): 0.0005\n",
            "('two', 'rooms'): 0.0007\n",
            "('rooms', 'four'): 0.0005\n",
            "('four', 'months'): 0.0005\n",
            "('months', 'in'): 0.0006\n",
            "('in', 'advance'): 0.0010\n",
            "('advance', 'at'): 0.0005\n",
            "('at', 'the'): 0.0281\n",
            "('the', 'talbott'): 0.0019\n"
          ]
        }
      ],
      "source": [
        "## K-SMOOTHING: BIGRAM - multiple values (a-d) ##\n",
        "\n",
        "# Apply K-Smoothing values ka -> kd\n",
        "bigram_probs_addka = {bigram: (count + ka) / (unigram_freq.get(bigram[0], 0) + ka * V) for bigram, count in bigram_counts.items()}\n",
        "bigram_probs_addkb = {bigram: (count + kb) / (unigram_freq.get(bigram[0], 0) + kb * V) for bigram, count in bigram_counts.items()}\n",
        "bigram_probs_addkc = {bigram: (count + kc) / (unigram_freq.get(bigram[0], 0) + kc * V) for bigram, count in bigram_counts.items()}\n",
        "bigram_probs_addkd = {bigram: (count + kd) / (unigram_freq.get(bigram[0], 0) + kd * V) for bigram, count in bigram_counts.items()}\n",
        "\n",
        "print(\"Add-k Smoothed Bigram Probabilities:\")\n",
        "print(\"K = 0.01:\")\n",
        "for bigram, prob in islice(bigram_probs_addka.items(), 10):\n",
        "    print(f\"{bigram}: {prob:.4f}\")\n",
        "print(\"K = 0.1:\")\n",
        "for bigram, prob in islice(bigram_probs_addkb.items(), 10):\n",
        "    print(f\"{bigram}: {prob:.4f}\")\n",
        "print(\"K = 0.3:\")\n",
        "for bigram, prob in islice(bigram_probs_addkc.items(), 10):\n",
        "    print(f\"{bigram}: {prob:.4f}\")\n",
        "print(\"K = 5:\")\n",
        "for bigram, prob in islice(bigram_probs_addkd.items(), 10):\n",
        "    print(f\"{bigram}: {prob:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83c56654-9082-4bc9-9f35-24bc8cc819e0",
      "metadata": {
        "id": "83c56654-9082-4bc9-9f35-24bc8cc819e0",
        "outputId": "f9d8f84d-3eb6-4c01-94a2-5fdf14c764ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsmoothed Unigram Perplexity: 254.7311\n",
            "Laplace Smoothed Unigram Perplexity: 255.7838\n",
            "Add-k: K = 0.01 Smoothed Unigram Perplexity: 254.7387\n",
            "Add-k: K = 0.1 Smoothed Unigram Perplexity: 254.8103\n",
            "Add-k: K = 0.3 Smoothed Unigram Perplexity: 254.9883\n",
            "Add-k: K = 5 Smoothed Unigram Perplexity: 263.1593\n",
            "\n",
            "Unsmoothed Bigram Perplexity: 23.1438\n",
            "Laplace Smoothed Bigram Perplexity: 95.3924\n",
            "Add-k: K = 0.01 Smoothed Bigram Perplexity: 26.5051\n",
            "Add-k: K = 0.1 Smoothed Bigram Perplexity: 39.6675\n",
            "Add-k: K = 0.3 Smoothed Bigram Perplexity: 56.4531\n",
            "Add-k: K = 5 Smoothed Bigram Perplexity: 232.4393\n"
          ]
        }
      ],
      "source": [
        "## CALCULATE PERPLEXITY ##\n",
        "\n",
        "# Function: to calulate perplexity\n",
        "# -- corpus: tokenized validation set\n",
        "# -- ngram_probs: previously calculated\n",
        "# -- n set to 1 for unigram and 2 for bigram\n",
        "# -- unk_prob set to 1e-10 so that log(0) = -âˆž doesn't break the code\n",
        "def calculate_perplexity(corpus, ngram_probs, n, unk_prob=1e-10):\n",
        "\n",
        "    #initialize variables\n",
        "    total_log_prob = 0\n",
        "    word_count = 0\n",
        "\n",
        "    for sentence in corpus:\n",
        "        if n == 1: # unigram\n",
        "            for word in sentence:\n",
        "                prob = ngram_probs.get(word, ngram_probs.get(\"<UNK>\", unk_prob))  # Use <UNK> prob if unigram is unknown\n",
        "                total_log_prob += np.log(prob)\n",
        "                word_count += 1\n",
        "        elif n == 2: # bigram\n",
        "            for i in range(1, len(sentence)):  # Start from the second word\n",
        "                bigram = (sentence[i - 1], sentence[i])\n",
        "                prob = ngram_probs.get(bigram, ngram_probs.get((\"<UNK>\", \"<UNK>\"), unk_prob))  # Use <UNK> prob if bigram is unknown\n",
        "                total_log_prob += np.log(prob)\n",
        "                word_count += 1\n",
        "\n",
        "    return np.exp(-total_log_prob / word_count)  # Perplexity formula\n",
        "\n",
        "# Compute perplexity for different models with the validation corpus\n",
        "unigram_perplexity = calculate_perplexity(val_corpus, unigram_probs, n=1)\n",
        "bigram_perplexity = calculate_perplexity(val_corpus, bigram_probs, n=2)\n",
        "unigram_perplexity_smoothed = calculate_perplexity(val_corpus, unigram_probs_smoothed, n=1)\n",
        "bigram_perplexity_smoothed = calculate_perplexity(val_corpus, bigram_probs_smoothed, n=2)\n",
        "unigram_perplexity_addka = calculate_perplexity(val_corpus, unigram_probs_addka, n=1)\n",
        "unigram_perplexity_addkb = calculate_perplexity(val_corpus, unigram_probs_addkb, n=1)\n",
        "unigram_perplexity_addkc = calculate_perplexity(val_corpus, unigram_probs_addkc, n=1)\n",
        "unigram_perplexity_addkd = calculate_perplexity(val_corpus, unigram_probs_addkd, n=1)\n",
        "bigram_perplexity_addka = calculate_perplexity(val_corpus, bigram_probs_addka, n=2)\n",
        "bigram_perplexity_addkb = calculate_perplexity(val_corpus, bigram_probs_addkb, n=2)\n",
        "bigram_perplexity_addkc = calculate_perplexity(val_corpus, bigram_probs_addkc, n=2)\n",
        "bigram_perplexity_addkd = calculate_perplexity(val_corpus, bigram_probs_addkd, n=2)\n",
        "\n",
        "# Print the perplexities\n",
        "print(f\"Unsmoothed Unigram Perplexity: {unigram_perplexity:.4f}\")\n",
        "print(f\"Laplace Smoothed Unigram Perplexity: {unigram_perplexity_smoothed:.4f}\")\n",
        "print(f\"Add-k: K = 0.01 Smoothed Unigram Perplexity: {unigram_perplexity_addka:.4f}\")\n",
        "print(f\"Add-k: K = 0.1 Smoothed Unigram Perplexity: {unigram_perplexity_addkb:.4f}\")\n",
        "print(f\"Add-k: K = 0.3 Smoothed Unigram Perplexity: {unigram_perplexity_addkc:.4f}\")\n",
        "print(f\"Add-k: K = 5 Smoothed Unigram Perplexity: {unigram_perplexity_addkd:.4f}\\n\")\n",
        "\n",
        "print(f\"Unsmoothed Bigram Perplexity: {bigram_perplexity:.4f}\")\n",
        "print(f\"Laplace Smoothed Bigram Perplexity: {bigram_perplexity_smoothed:.4f}\")\n",
        "print(f\"Add-k: K = 0.01 Smoothed Bigram Perplexity: {bigram_perplexity_addka:.4f}\")\n",
        "print(f\"Add-k: K = 0.1 Smoothed Bigram Perplexity: {bigram_perplexity_addkb:.4f}\")\n",
        "print(f\"Add-k: K = 0.3 Smoothed Bigram Perplexity: {bigram_perplexity_addkc:.4f}\")\n",
        "print(f\"Add-k: K = 5 Smoothed Bigram Perplexity: {bigram_perplexity_addkd:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "905e79e8-0644-406f-a66e-71a33e7009cb",
      "metadata": {
        "id": "905e79e8-0644-406f-a66e-71a33e7009cb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}